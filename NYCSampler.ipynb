{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./NYC_dataset/volume_test.npz', './NYC_dataset/volume_train.npz']\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob('./NYC_dataset/*.npz')\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npz(filename, col='volume'):\n",
    "    return np.load(filename)[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (1920, 10, 20, 2) , Test shape:  (960, 10, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_npz(filenames[1])\n",
    "test_dataset = load_npz(filenames[0])\n",
    "print(\"Train shape: \", np.shape(train_dataset), \", Test shape: \", np.shape(test_dataset))\n",
    "start_train, end_train = train_dataset[:,:,:,0], train_dataset[:,:,:,1]\n",
    "start_test, end_test = test_dataset[:,:,:,0], test_dataset[:,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Some Parameters \n",
    "num_train, num_test = np.shape(start_train)[0], np.shape(start_test)[0]\n",
    "num_row = num_train + num_test #1960+960\n",
    "\n",
    "# Holiday and Prev.Holiday List\n",
    "holiday_dict = {1:[1, 19], 2:[16]}\n",
    "prev_holiday_dict = {1:[18], 2:[15]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Temporal Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize numpy array of temporal information (one-hot encoding)\n",
    "datasets_min_30 = np.zeros([num_row, 48])\n",
    "datasets_dow = np.zeros([num_row, 7])\n",
    "datasets_holiday = np.zeros([num_row, 1])\n",
    "datasets_prev_holiday = np.zeros([num_row, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 mins, and day-of-week index are calculated below\n",
    "for i in range(num_row):\n",
    "    idx_30 = int(int(i)%48)\n",
    "    idx_dow = int(int(i/48)%7)\n",
    "    datasets_min_30[i,idx_30] = 1\n",
    "    datasets_dow[i, idx_dow] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day of Holiday 01/01 ~:  [1, 19, 47]\n",
      "Day of Prev.Holiday (2018/01/01 ~):  [18, 46]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of day after 1-1 (on Holiday)\n",
    "prev_month_dict={1:0, 2:31, 3:59, 4:90, 5:120, 6:151}\n",
    "holiday_list, prev_holiday_list = [], []\n",
    "for key in holiday_dict.keys():\n",
    "    for value in holiday_dict[key]:\n",
    "        holiday_list.extend([prev_month_dict[key]+value])\n",
    "    for value in prev_holiday_dict[key]:\n",
    "        prev_holiday_list.extend([prev_month_dict[key]+value])\n",
    "print(\"Day of Holiday 0101 ~: \", holiday_list)\n",
    "print(\"Day of Prev.Holiday (2018/01/01 ~): \", prev_holiday_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day of Holiday (01/01 ~):  [0, 18, 46]\n",
      "Day of Prev.Holiday (01/01 ~):  [17, 45]\n"
     ]
    }
   ],
   "source": [
    "# For convicience, we substitute 1, to indicate index\n",
    "holiday_list = [value -1 for value in holiday_list]\n",
    "prev_holiday_list = [value -1 for value in prev_holiday_list]\n",
    "print(\"Day of Holiday (01/01 ~): \", holiday_list)\n",
    "print(\"Day of Prev.Holiday (01/01 ~): \", prev_holiday_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_row):\n",
    "    is_holiday = int(i/48) in holiday_list\n",
    "    is_prev_holiday = int(i/48) in prev_holiday_list\n",
    "    if is_holiday:\n",
    "        datasets_holiday[i,0] = 1\n",
    "    if is_prev_holiday:\n",
    "        datasets_prev_holiday[i,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./NYC_dataset/NYC_min_30_dataset.npz', datasets_min_30)\n",
    "np.savez('./NYC_dataset/NYC_day_of_week_dataset.npz', datasets_dow)\n",
    "np.savez('./NYC_dataset/NYC_holiday_dataset.npz', datasets_holiday)\n",
    "np.savez('./NYC_dataset/NYC_prev_holiday_dataset.npz', datasets_prev_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_min_10 = load_npz('kakao_min_10_dataset.npz')\n",
    "dataset_min_30 = load_npz('./NYC_dataset/NYC_min_30_dataset.npz', 'arr_0')\n",
    "dataset_dow = load_npz('./NYC_dataset/NYC_day_of_week_dataset.npz', 'arr_0')\n",
    "dataset_holiay = load_npz('./NYC_dataset/NYC_holiday_dataset.npz', 'arr_0')\n",
    "dataset_prev_holiday = load_npz('./NYC_dataset/NYC_prev_holiday_dataset.npz', 'arr_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 48) (2880, 7) (2880, 1) (2880, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(dataset_min_30), np.shape(dataset_dow), np.shape(dataset_holiay), np.shape(dataset_prev_holiday))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, idx):\n",
    "    return data[:idx], data[idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train&Test Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = num_train #144 # 120 days and 144 time index\n",
    "min_30_train, min_30_test=train_test_split(dataset_min_30, train_index)\n",
    "dow_train, dow_test=train_test_split(dataset_dow, train_index)\n",
    "holiday_train, holiday_test=train_test_split(dataset_holiay, train_index)\n",
    "prev_holiday_train, prev_holiday_test=train_test_split(dataset_prev_holiday, train_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAG = 8\n",
    "END_LAG = 16\n",
    "STEP = 1 #6\n",
    "BIAS = END_LAG - LAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler(data, lag=8, bias=0, step=1, temp=False):\n",
    "    \"\"\"This function makes samples of the time series data\n",
    "    args:\n",
    "    - data : (# of data, height, width)\n",
    "    - lag : the length of sampling\n",
    "    - step : (step)-ahead forecasting label\n",
    "    return: \n",
    "    - data_x (# of sample, height, width, lag)\n",
    "    - data_y (# of sample, height, width, 1)\n",
    "    \"\"\"\n",
    "    num_row = len(data)\n",
    "    data_x, data_y = [], []\n",
    "    for idx in range(num_row):\n",
    "        strat_idx = idx + bias\n",
    "        try:\n",
    "            y = np.array(data[strat_idx+lag+(step-1)])\n",
    "            data_y.append(y)\n",
    "            if not temp:\n",
    "                x = np.transpose(data[strat_idx:strat_idx+lag], [1,2,0])\n",
    "                data_x.append(x)\n",
    "        except:\n",
    "            if len(np.shape(data_y)) <4 and not temp:\n",
    "                data_y = np.expand_dims(data_y, axis=-1)\n",
    "            print(\"Sampler Return\", np.shape(data_x), np.shape(data_y))\n",
    "            break\n",
    "            \n",
    "    if not temp:\n",
    "        return np.array(data_x), np.array(data_y)\n",
    "    else:\n",
    "        return np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler Return (1904, 10, 20, 8) (1904, 10, 20, 1)\n",
      "Sampler Return (944, 10, 20, 8) (944, 10, 20, 1)\n",
      "Sampler Return (1904, 10, 20, 16) (1904, 10, 20, 1)\n",
      "Sampler Return (944, 10, 20, 16) (944, 10, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "start_train_x, start_train_y = sampler(start_train, lag=LAG, bias=BIAS, step=STEP)\n",
    "start_test_x, start_test_y = sampler(start_test, lag=LAG, bias=BIAS, step=STEP)\n",
    "end_train_x, end_train_y = sampler(end_train, lag=END_LAG, step=STEP)\n",
    "end_test_x, end_test_y = sampler(end_test, lag=END_LAG, step=STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.shape(start_train_y)[0] == np.shape(end_train_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler Return (0,) (1904, 48)\n",
      "Sampler Return (0,) (944, 48)\n",
      "Sampler Return (0,) (1904, 7)\n",
      "Sampler Return (0,) (944, 7)\n",
      "Sampler Return (0,) (1904, 1)\n",
      "Sampler Return (0,) (944, 1)\n",
      "Sampler Return (0,) (1904, 1)\n",
      "Sampler Return (0,) (944, 1)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "min_10_train_y = sampler(min_10_train, lag=LAG, step=STEP, temp=True)\n",
    "min_10_test_y = sampler(min_10_test, lag=LAG, step=STEP, temp=True)\n",
    "'''\n",
    "min_30_train_y = sampler(min_30_train, lag=END_LAG, step=STEP, temp=True)\n",
    "min_30_test_y = sampler(min_30_test, lag=END_LAG, step=STEP, temp=True)\n",
    "\n",
    "dow_train_y = sampler(dow_train, lag=END_LAG, step=STEP, temp=True)\n",
    "dow_test_y = sampler(dow_test, lag=END_LAG, step=STEP, temp=True)\n",
    "\n",
    "holiday_train_y = sampler(holiday_train, lag=END_LAG, step=STEP, temp=True)\n",
    "holiday_test_y = sampler(holiday_test, lag=END_LAG, step=STEP, temp=True)\n",
    "\n",
    "prev_holiday_train_y = sampler(prev_holiday_train, lag=END_LAG, step=STEP, temp=True)\n",
    "prev_holiday_test_y = sampler(prev_holiday_test, lag=END_LAG, step=STEP, temp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1904, 57) (944, 57)\n"
     ]
    }
   ],
   "source": [
    "temporal_train = np.concatenate((dow_train_y, min_30_train_y, prev_holiday_train_y, holiday_train_y), axis=-1)\n",
    "temporal_test = np.concatenate((dow_test_y, min_30_test_y, prev_holiday_test_y, holiday_test_y), axis=-1)\n",
    "print(np.shape(temporal_train), np.shape(temporal_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Remark\n",
    "For fair comparision with STDN setting, we only use 477 number of test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./NYC_taxi_dataset/x_st_train.npz', start_train_x)\n",
    "np.savez('./NYC_taxi_dataset/x_st_test.npz', start_test_x[-477:])\n",
    "np.savez('./NYC_taxi_dataset/x_end_train.npz', end_train_x)\n",
    "np.savez('./NYC_taxi_dataset/x_end_test.npz', end_test_x[-477:])\n",
    "np.savez('./NYC_taxi_dataset/y_st_train.npz', start_train_y)\n",
    "np.savez('./NYC_taxi_dataset/y_st_test.npz', start_test_y[-477:])\n",
    "np.savez('./NYC_taxi_dataset/temporal_train.npz', temporal_train)\n",
    "np.savez('./NYC_taxi_dataset/temporal_test.npz', temporal_test[-477:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num, h, w = np.shape(start_train_y)[:-1]\n",
    "test_num = np.shape(start_test_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 10, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "coord_y = np.expand_dims(np.array([[y]*w for y in range(h)]), axis=-1)\n",
    "coord_x = np.expand_dims(np.array([[x]*h for x in range(w)]), axis=-1)\n",
    "coord_x = np.transpose(coord_x, [1,0,2])\n",
    "coord_xy = np.concatenate([coord_y, coord_x], axis=-1)\n",
    "coord_xy = np.repeat(np.expand_dims(coord_xy, axis=0), repeats=num_row, axis=0)\n",
    "print(np.shape(coord_xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1904, 10, 20, 2) (477, 10, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "coord_train, coord_test = coord_xy[:len(start_train_y)], coord_xy[-477:]\n",
    "print(np.shape(coord_train), np.shape(coord_test))\n",
    "np.savez('./NYC_taxi_dataset/coord_train.npz', coord_train)\n",
    "np.savez('./NYC_taxi_dataset/coord_test.npz', coord_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
